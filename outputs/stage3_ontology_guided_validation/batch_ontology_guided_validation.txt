====================================================================================================
COMPREHENSIVE VALIDATION REPORT
====================================================================================================

====================================================================================================
1. OVERALL STATISTICS
====================================================================================================

Document Processing (from Stage 1 metadata):
  • Total Documents Processed: 5
  • Total Pages Analyzed: 228 (from original PDF documents)
  • Total Segments Processed: 60 (text chunks used for extraction)

Knowledge Graph Statistics (from Stage 2 extraction):
  • Total Entities Extracted: 364
  • Total Metrics Identified: 266

====================================================================================================
2. EVALUATION METRICS SUMMARY
====================================================================================================

IMPORTANT: All metrics are calculated at the DOCUMENT LEVEL (not per-segment or per-page)

Key Performance Metrics:

1. Schema Compliance (%) - STRUCTURAL VALIDATION

   The 6 Critical Rules (All Critical):
   • VR001: Entity Uniqueness - All entity IDs must be unique
   • VR002: Entity Type-Specific Schema Compliance - Each entity type has required fields
           (Metric: measurement_type, metric_type, unit, code, description)
           (Model: description, equation, input_variables)
           (Category: section_title)
   • VR003: Metric Property Values - DirectMetric/CalculatedMetric code ≠ N/A; Quantitative unit ≠ N/A
   • VR004: Model Property Values - Models must have non-empty input_variables list
   • VR005: Relationship Predicate Validity - Only 5 allowed predicates
           (ConsistOf, Include, IsCalculatedBy, ReportUsing, RequiresInputFrom)
   • VR006: CalculatedMetric-Model Links - All CalculatedMetrics must have IsCalculatedBy → Model

   Definition: Average of per-rule granular scores across all 6 rules
   Formula: Average of [(Passed Items / Total Items) × 100%] per rule
   Approach: Rule-Level Weighted Average
   Scope: PER DOCUMENT (granular scoring per rule)

   How it works:
   • Each rule calculates its own score based on items checked
   • VR001 checks all entities for uniqueness → score = (unique / total) × 100%
   • VR002 checks all entities for required fields → score = (valid / total) × 100%
   • VR003 checks all Metrics for property values → score = (valid / total_metrics) × 100%
   • VR004 checks only Models for input_variables → score = (valid / total_models) × 100%
   • VR005 checks all relationships for valid predicates → score = (valid / total_rels) × 100%
   • VR006 checks only CalculatedMetrics for Model links → score = (valid / total_calc_metrics) × 100%
   • Overall compliance = average of all 6 rule scores

   Interpretation:
   • 100% = All items in all rules passed (perfect compliance)
   • 84.95% = Average score showing some items failed (provides granular quality insight)
   • 10.1% = Low score indicating significant violations (shows severity of issues)

   Example:
   • VR002 has 7/69 entities passing → Score: 10.1%
   • Shows 62 entities need schema fixes, provides actionable improvement target

2. Semantic Accuracy (%) - ENTITY SEMANTIC VALIDATION
   Definition: % of entities with semantically correct type assignments
   Formula: (Correctly Typed Entities / Total Entities) × 100%
   Scope: PER ENTITY (each entity independently validated)
   Validation Method: Claude LLM checks if entity label/description matches its assigned type

   Example:
   • Entity: {type: 'Metric', label: 'Scope 1 Emissions'}
   • LLM Question: 'Does "Scope 1 Emissions" semantically represent a Metric?'
   • Answer: YES → Semantically Correct

   Interpretation:
   • 100% = All entity types are semantically correct
   • 80% = 20% of entities have incorrect type assignments
   • Cost: LLM validation cost tracked in semantic_validation.llm_cost

3. Relationship Retention (%) - CASCADE FILTERING
   Definition: % of relationships retained after entity semantic filtering
   Formula: (Retained Relationships / Original Relationships) × 100%
   Scope: PER RELATIONSHIP (but DEPENDENT on entity validation)

   How it works (CASCADE effect):
   • Step 1: Entities are validated for semantic correctness
   • Step 2: Entities failing semantic validation are REMOVED
   • Step 3: Relationships referencing removed entities are ALSO removed (cascade)
   • Retention Rate = % of relationships that survived this cascade

   Example:
   • Original: 100 relationships
   • Entity semantic validation removes 10 entities
   • 15 relationships reference these 10 removed entities
   • Result: 85 relationships retained → 85% retention rate

   Interpretation:
   • 100% = All relationships retained (no entities removed, fully connected graph)
   • 80% = 20% of relationships removed (graph connectivity reduced)
   • 0% = All relationships removed (completely disconnected graph)

   IMPORTANT: This is NOT an independent validation of relationships themselves.
              Relationships are only removed if their connected entities fail semantic validation.

Document                              Schema Compliance%        Semantic Acc%      Rel. Retention%
--------------------------------------------------------------------------------------------------
1. SASB-commercial-banks-standard_e                 82.7                 79.2                 79.2
1.SASB-semiconductors-standard_en-g                 82.0                 89.9                 90.1
1.issb(sasb)-general-a-ifrs-s2-clim                 81.5                 85.0                 89.2
2.Australia-AASBS2_09-24                            83.3                 89.2                 86.7
2.FINAL-2017-TCFD-Report                            80.1                 64.8                 62.8

Interpretation:

Example: 1. SASB-commercial-banks-standard_en-gb
  • Schema Compliance = 82.7%
    (Average of per-rule granular scores - Rule-Level Weighted Average)
  • Semantic Accuracy = 79.2%
    (42/53 entities semantically correct)
    (LLM validation cost: $0.0053)
  • Relationship Retention = 79.2%
    (42/53 relationships retained)

Total Semantic Validation Cost: $0.0364
  • Across 5 document(s)
  • Average cost per document: $0.0073

Note: Metrics are calculated from validation_metadata in validated JSON files

====================================================================================================
3. DOCUMENT SUMMARY TABLE
====================================================================================================

Shows pipeline data flow: Stage 1 (parsing) → Stage 2 (extraction) → Stage 3 (validation)

Document                                    Pages   Segments Stage2 Entities Stage3 Entities  Stage2 Rels  Stage3 Rels
------------------------------------------------------------------------------------------------------------------------
1. SASB-commercial-banks-standard_en-gb        23         10              53              42           53           42
1.SASB-semiconductors-standard_en-gb           27         13              69              62           71           64
1.issb(sasb)-general-a-ifrs-s2-climate-r       46         10              80              68           65           58
2.Australia-AASBS2_09-24                       58          8              74              66           75           65
2.FINAL-2017-TCFD-Report                       74         19              88              57           86           54

====================================================================================================
3a. ENTITY TYPE DISTRIBUTION SUMMARY (All Documents)
====================================================================================================

Shows entity type counts aggregated across all documents for Stage 2 (extraction) and Stage 3 (validation)

Retention (%): Calculated as (Stage 3 Count / Stage 2 Count) × 100% for each entity type
Filtering Mechanism: Entities removed based on semantic type validation (LLM-validated correctness)

Entity Type                 Stage 2 Count   Stage 3 Count   Retention (%)
---------------------------------------------------------------------------
Industry                               20              14            70.0
ReportingFramework                      5               5           100.0
Category                               44              40            90.9
Metric                                266             207            77.8
Model                                  29              29           100.0
---------------------------------------------------------------------------
TOTAL                                 364             295            81.0

====================================================================================================
3b. RELATIONSHIP PREDICATE DISTRIBUTION SUMMARY (All Documents)
====================================================================================================

Shows relationship predicate counts aggregated across all documents for Stage 2 (extraction) and Stage 3 (validation)

Retention (%): Calculated as (Stage 3 Count / Stage 2 Count) × 100% for each predicate type
Filtering Mechanism: Cascade removal (relationships removed when their connected entities fail semantic validation)
Note: Relationships are NOT independently validated - only removed if subject/object entities are removed

Relationship Predicate           Stage 2 Count   Stage 3 Count   Retention (%)
---------------------------------------------------------------------------
ConsistOf                                  178             140            78.7
Include                                     43              39            90.7
IsCalculatedBy                              30              30           100.0
ReportUsing                                 15              13            86.7
RequiresInputFrom                           84              61            72.6
---------------------------------------------------------------------------
TOTAL                                      350             283            80.9

====================================================================================================
4. VALIDATION RULES SUMMARY (All Documents)
====================================================================================================

Rule ID    Rule Name                            1. SASB-commerc  1.SASB-semicond  1.issb(sasb)-ge  2.Australia-AAS  2.FINAL-2017-TC
------------------------------------------------------------------------------------------------------------------------------------
VR001      Entity Uniqueness                             ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS
VR002      Entity Type-Specific Schema Complia      ❌ FAIL (42)      ❌ FAIL (62)      ❌ FAIL (68)      ❌ FAIL (66)      ❌ FAIL (57)
VR003      Metric Property Values                    ❌ FAIL (1)       ❌ FAIL (3)       ❌ FAIL (6)           ✅ PASS       ❌ FAIL (7)
VR004      Model Property Values                         ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS
VR005      Relationship Predicate Validity               ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS
VR006      CalculatedMetric-Model Links                  ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS           ✅ PASS

====================================================================================================
5. PROVENANCE QUALITY ANALYSIS
====================================================================================================

Provenance Methodology:
  • Each entity contains provenance.segment_id linking to stage1 segments
  • Each segment contains page_start and page_end fields
  • Therefore: Entity → segment_id → Segment → page numbers (complete traceability)

Calculation:
  • With Provenance (%) = (Entities with segment_id / Total Entities) × 100
  • With Timestamp (%) = (Entities with extraction_timestamp / Total Entities) × 100

Document                                  Total Entities       With Provenance (%)        With Timestamp (%)
---------------------------------------------------------------------------------------------------------
1. SASB-commercial-banks-standard_en-gb               53                     100.0                     100.0
1.SASB-semiconductors-standard_en-gb                  69                     100.0                     100.0
1.issb(sasb)-general-a-ifrs-s2-climate-r              80                     100.0                     100.0
2.Australia-AASBS2_09-24                              74                     100.0                     100.0
2.FINAL-2017-TCFD-Report                              88                     100.0                     100.0

====================================================================================================
5. METRICS REFERENCE & CALCULATION GUIDE
====================================================================================================

This section provides comprehensive documentation of all metrics used in Stage 3 validation.
For complete details, see: result_visualisation_and_analysis/METRICS_REFERENCE.txt

----------------------------------------------------------------------------------------------------
5.1 STAGE 3 VALIDATION METRICS (Enhanced Metadata)
----------------------------------------------------------------------------------------------------

All enhanced metrics are stored in validated JSON files under 'validation_metadata' section.

QUALITY METRICS (quality_metrics section):

  • Validation Pass Rate (%)
    Formula: (Critical Rules Passed / Total Critical Rules) × 100
    Where: Total Critical Rules = 6 (VR001-VR006, All Critical)
    Unit: Percentage (0-100%)
    Aggregation: Document-level
    Data Source: Stage 3 validation results (rule_compliance section)
    Interpretation:
      - 100% = All validation rules passed (perfect schema compliance)
      - 83.3% = 1 rule failed (5/6 passed)
      - Measures schema compliance and data quality

  • Relationship Retention Rate (%)
    Formula: (Validated Relationships / Original Relationships) × 100
    Unit: Percentage (0-100%)
    Aggregation: Document-level
    Data Source: original_relationship_count + validated_relationship_count
    Interpretation:
      - 100% = All relationships valid
      - 0% = All relationships invalid (common in baseline method)

RULE COMPLIANCE (rule_compliance section):

  • critical_rules_total: Always 6 (VR001-VR006)
  • critical_rules_passed_count: Number of rules that passed (0-6)
  • critical_rules_failed_count: Number of rules that failed (0-6)
  • critical_rules_failed: List of specific failed rule IDs
  • pass_rate_percentage: Same as Validation Pass Rate

VIOLATION STATISTICS (violation_statistics section):

  • total_violations: Total number of rule violations across all rules
  • entities_with_violations: Count of entities that were removed
  • relationships_with_violations: Count of relationships that were removed
  • violations_by_rule: Per-rule breakdown
    - Each rule ID (VR001-VR010) shows:
      * passed: boolean (true/false)
      * violation_count: integer count

SEGMENT STATISTICS (segment_statistics section):

  • total_segments: Number of text segments in document
  • segments_with_entities: Segments that contained entities
  • entities_per_segment: Per-segment entity counts
    - Format: {segment_id: {original: int, validated: int}}
    - Shows exactly how many entities filtered per segment
  • retention_per_segment: Per-segment retention rates (%)
    - Format: {segment_id: retention_percentage}
    - Enables identification of problematic segments
  • avg_segment_retention: Average retention across all segments (%)

----------------------------------------------------------------------------------------------------
5.2 AGGREGATION LEVELS
----------------------------------------------------------------------------------------------------

SEGMENT-LEVEL (Most Granular):
  • Source: Individual text chunks from Stage 1 (e.g., seg_001, seg_002)
  • Metrics Available:
    - entities_per_segment (original + validated counts)
    - retention_per_segment (retention %)
  • Use Cases:
    - Identify problematic document sections
    - Trace entities back to source text
    - Target re-extraction at specific segments

DOCUMENT-LEVEL (Aggregated from Segments):
  • Source: Aggregated from all segments in one document
  • Metrics Available:
    - All quality_metrics (schema_compliance_weighted, semantic_type_accuracy, relationship_retention_rate)
    - All rule_compliance metrics
    - All violation_statistics
    - avg_segment_retention
  • Use Cases:
    - Compare documents to each other
    - Assess overall document quality
    - Report per-document performance

METHOD-LEVEL (Aggregated from Documents):
  • Source: Aggregated across all documents for one method
    - Ontology-Guided: All documents processed with ontology-guided extraction
    - Baseline: All documents processed with baseline LLM extraction
  • Metrics Available:
    - Average schema_compliance_weighted across all documents
    - Average semantic_type_accuracy and relationship_retention_rate across all documents
    - Total entities extracted/validated
  • Use Cases:
    - Compare Ontology-Guided vs Baseline methods
    - Report overall pipeline performance
    - Visualizations in result_visualisation_and_analysis/

----------------------------------------------------------------------------------------------------
5.3 FILE LOCATIONS
----------------------------------------------------------------------------------------------------

STAGE 3 VALIDATION OUTPUTS:

  Ontology-Guided Method:
    • outputs/stage3_ontology_guided_validation/[document]_validated.json
    • Contains: All enhanced metrics in 'validation_metadata' section

  Baseline Method:
    • outputs/stage3_baseline_llm_comparison/[document]_validated.json
    • Contains: All enhanced metrics in 'validation_metadata' section

VISUALIZATION OUTPUTS:
    • result_visualisation_and_analysis/stage3_comparison/
      - validation_quality.png (Validation Pass Rate + Entity Retention)
      - validation_quality.csv (Data table)
      - validation_quality_EXPLANATION.txt (Formulas + interpretation)
      - filtering_impact.png (Entities filtered)
      - filtering_impact.csv (Data table)
      - filtering_impact_EXPLANATION.txt (Formulas + interpretation)

COMPREHENSIVE METRICS DOCUMENTATION:
    • result_visualisation_and_analysis/METRICS_REFERENCE.txt
      - Complete reference for all metrics
      - Formulas, data sources, interpretations
      - Covers Stage 2, Stage 3, and visualization metrics

====================================================================================================
END OF REPORT
====================================================================================================